# backend/main.py

import os
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Optional

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

from dotenv import load_dotenv
from openai import OpenAI, OpenAIError, APIError, APIConnectionError, RateLimitError, APITimeoutError

import chromadb
from chromadb.utils import embedding_functions

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ================== ê¸°ë³¸ ì„¤ì • ==================

BASE_DIR = Path(__file__).resolve().parent
RAG_DIR = BASE_DIR / "rag"
DB_DIR = RAG_DIR / "db"

COLLECTION_NAME = "yeobaek_docs"
EMBED_MODEL = "text-embedding-3-small"

load_dotenv()  # .env ì½ê¸°
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise RuntimeError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .envë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

# OpenAI í´ë¼ì´ì–¸íŠ¸
client = OpenAI(api_key=api_key)


# ================== Chroma / RAG(1119 ì‹ ê·œ) ==================

def get_rag_collection():
    """ì €ì¥ëœ ì¸ë±ìŠ¤ë¥¼ ë¶ˆëŸ¬ì™€ì„œ ì»¬ë ‰ì…˜ ê°ì²´ë¥¼ ë¦¬í„´"""
    if not DB_DIR.exists():
        logger.error(f"RAG DB ë””ë ‰í„°ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {DB_DIR}")
        raise HTTPException(
            status_code=503,
            detail="RAG ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
        )

    try:
        chroma_client = chromadb.PersistentClient(path=str(DB_DIR))
    except Exception as e:
        logger.error(f"ChromaDB ì—°ê²° ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=503,
            detail="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        )

    try:
        openai_ef = embedding_functions.OpenAIEmbeddingFunction(
            api_key=api_key,
            model_name=EMBED_MODEL,
        )
    except Exception as e:
        logger.error(f"OpenAI Embedding í•¨ìˆ˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=503,
            detail="ì„ë² ë”© ì„œë¹„ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        )

    try:
        collection = chroma_client.get_or_create_collection(
            name=COLLECTION_NAME,
            embedding_function=openai_ef,
        )
        return collection
    except Exception as e:
        logger.error(f"ì»¬ë ‰ì…˜ ì ‘ê·¼ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=503,
            detail="ë°ì´í„° ì»¬ë ‰ì…˜ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )


def make_context_str(documents: List[str], metadatas: List[dict]) -> str:
    """
    ê²€ìƒ‰ëœ ì²­í¬ë“¤ì„ í•˜ë‚˜ì˜ í° context ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸°.
    ê° ì²­í¬ ì•ì— [ì¶œì²˜: íŒŒì¼ëª…, chunk: n] ê¼¬ë¦¬í‘œë¥¼ ë¶™ì„.
    """
    blocks = []
    for doc, meta in zip(documents, metadatas):
        source = meta.get("source", "unknown")
        idx = meta.get("chunk_index", 0)
        header = f"[ì¶œì²˜: {source} | chunk #{idx}]"
        blocks.append(header + "\n" + doc.strip())
    return "\n\n---\n\n".join(blocks)


# ================== ë¡œê·¸ ì„¤ì • (ì˜µì…˜, 1119 ì‹ ê·œ) ==================

LOG_PATH = BASE_DIR / "logs" / "chat_logs.jsonl"
LOG_PATH.parent.mkdir(exist_ok=True)


def log_chat(user_message: str, reply: str, meta: Optional[dict] = None):
    """ëŒ€í™” í•œ ê±´ì„ jsonl í˜•ì‹ìœ¼ë¡œ ê¸°ë¡"""
    entry = {
        "timestamp": datetime.utcnow().isoformat(),
        "user_message": user_message,
        "reply": reply,
        "meta": meta or {},
    }
    with LOG_PATH.open("a", encoding="utf-8") as f:
        f.write(json.dumps(entry, ensure_ascii=False) + "\n")


# ================== FastAPI ì•± ==================

app = FastAPI(title="Yeobaek Chat Backend")

# CORS ì„¤ì •
# í™˜ê²½ ë³€ìˆ˜ë¡œë¶€í„° í—ˆìš©í•  origin ì½ê¸° (í”„ë¡œë•ì…˜ í™˜ê²½ ëŒ€ì‘)
ALLOWED_ORIGINS = os.getenv(
    "ALLOWED_ORIGINS",
    "http://localhost:5173,http://127.0.0.1:5173"
).split(",")

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST"],  # í•„ìš”í•œ ë©”ì„œë“œë§Œ í—ˆìš©
    allow_headers=["Content-Type", "Authorization"],  # í•„ìš”í•œ í—¤ë”ë§Œ í—ˆìš©
)


# ================== ëª¨ë¸ ì •ì˜ ==================

class ChatRequest(BaseModel):
    message: str


class ChatResponse(BaseModel):
    reply: str


# ================== ì—”ë“œí¬ì¸íŠ¸ ==================

# ping test
@app.get("/api/ping")
def ping():
    return {"status": "ok"}


# 1) ì¼ë°˜ LLM Chat (RAG X)
@app.post("/api/chat", response_model=ChatResponse)
def chat(req: ChatRequest):
    if not req.message or not req.message.strip():
        raise HTTPException(status_code=400, detail="ë©”ì‹œì§€ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    try:
        completion = client.chat.completions.create(
            model="gpt-4o-mini",  # ì˜¬ë°”ë¥¸ ëª¨ë¸ëª…ìœ¼ë¡œ ìˆ˜ì •
            messages=[
                {
                    "role": "system",
                    "content": (
                        "You are a helpful assistant for Yeobaek club. "
                        "Answer briefly in Korean unless the user asks otherwise."
                    ),
                },
                {"role": "user", "content": req.message},
            ],
            timeout=30.0,  # íƒ€ì„ì•„ì›ƒ 30ì´ˆ ì„¤ì •
        )
        reply_text = completion.choices[0].message.content
        log_chat(
            user_message=req.message,
            reply=reply_text,
            meta={"model": "gpt-4o-mini", "source": "openai", "mode": "plain"},
        )
        return ChatResponse(reply=reply_text)

    except RateLimitError as e:
        logger.error(f"OpenAI Rate Limit ì—ëŸ¬: {e}")
        raise HTTPException(
            status_code=429,
            detail="ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        )
    except APITimeoutError as e:
        logger.error(f"OpenAI Timeout ì—ëŸ¬: {e}")
        raise HTTPException(
            status_code=504,
            detail="ìš”ì²­ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        )
    except APIConnectionError as e:
        logger.error(f"OpenAI ì—°ê²° ì—ëŸ¬: {e}")
        raise HTTPException(
            status_code=503,
            detail="AI ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        )
    except APIError as e:
        logger.error(f"OpenAI API ì—ëŸ¬: {e}")
        raise HTTPException(
            status_code=502,
            detail="AI ì„œë¹„ìŠ¤ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ (/api/chat): {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail="ë‹µë³€ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )


# 2) RAG + LLM Chat(1119 ì‹ ê·œ)
@app.post("/api/rag-chat", response_model=ChatResponse)
def rag_chat(req: ChatRequest):
    """
    1) ì‚¬ìš©ìì˜ ì§ˆë¬¸ìœ¼ë¡œ ChromaDBì—ì„œ ê´€ë ¨ ì²­í¬ ê²€ìƒ‰
    2) ê²€ìƒ‰ëœ ë‚´ìš©(context)ì„ ë¶™ì—¬ì„œ OpenAIì—ê²Œ ì§ˆë¬¸
    3) Yeobaek/LIS ë„ë©”ì¸ ë‹µë³€ì„ ìƒì„±í•´ì„œ ë°˜í™˜
    """
    query = req.message.strip()
    if not query:
        raise HTTPException(status_code=400, detail="messageê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    try:
        collection = get_rag_collection()

        # 1) ë²¡í„° ê²€ìƒ‰ (Chromaê°€ ë‚´ë¶€ì ìœ¼ë¡œ ì„ë² ë”© ê³„ì‚°)
        try:
            results = collection.query(
                query_texts=[query],
                n_results=4,  # ìƒìœ„ 4ê°œ ì²­í¬ ì‚¬ìš©
            )
        except Exception as e:
            logger.error(f"ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            raise HTTPException(
                status_code=503,
                detail="ë¬¸ì„œ ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            )

        docs = results.get("documents", [[]])[0]
        metas = results.get("metadatas", [[]])[0]

        if not docs:
            # ë¬¸ì„œë¥¼ ëª» ì°¾ì€ ê²½ìš°: ì¼ë°˜ ë‹µë³€ìœ¼ë¡œ fallback
            fallback = (
                "ì•„ì§ ì¸ë±ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”.\n"
                "ê·¸ë˜ë„ ì¼ë°˜ ì§€ì‹ ê¸°ë°˜ìœ¼ë¡œ ìµœëŒ€í•œ ë‹µë³€í•´ë³¼ê²Œìš” ğŸ™‚"
            )
            context = ""
        else:
            context = make_context_str(docs, metas)
            fallback = None

        # 2) OpenAIì—ê²Œ context + ì§ˆë¬¸ ì „ë‹¬
        system_prompt = (
            "ë„ˆëŠ” ì¸ì²œëŒ€í•™êµ ë¬¸í—Œì •ë³´í•™ê³¼ ë™ì•„ë¦¬ 'ì—¬ë°±(Yeobaek)'ì˜ "
            "ì „ë¬¸ ë„ì„œê´€Â·ì •ë³´í•™(LIS) ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.\n"
            "- ì£¼ìš” ë„ë©”ì¸: ë¬¸í—Œì •ë³´í•™, ì •ë³´ê²€ìƒ‰(IR), ë©”íƒ€ë°ì´í„°/ëª©ë¡, ë¶„ë¥˜(KDC/DDC), "
            "ë””ì§€í„¸ ì•„ì¹´ì´ë¹™, ì¶”ì²œ ì‹œìŠ¤í…œ, ì‹œì†ŒëŸ¬ìŠ¤/ì˜¨í†¨ë¡œì§€, ë™ì•„ë¦¬ ìš´ì˜.\n"
            "- ì•„ë˜ ì œê³µëœ 'ì—¬ë°± í”„ë¡œì íŠ¸ ë¬¸ì„œ' ë‚´ìš©ì„ ìš°ì„ ì ìœ¼ë¡œ ì°¸ê³ í•´ì„œ ë‹µë³€í•´.\n"
            "- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì•„ëŠ” ì²™í•˜ì§€ ë§ê³ , í™•ì‹¤íˆ ëª¨ë¥¸ë‹¤ê³  ë§í•´.\n"
            "- ë‹µë³€ì€ í•œêµ­ì–´, 3~6ë¬¸ì¥ ì •ë„ë¡œ ê°„ê²°í•˜ê²Œ.\n"
            "- í•„ìš”í•˜ë©´ ì–´ë–¤ ë¬¸ì„œë¥¼ ì°¸ê³ í–ˆëŠ”ì§€ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´."
        )

        user_content = query
        if context:
            user_content = (
                "ë‹¤ìŒì€ ì—¬ë°± í”„ë¡œì íŠ¸ ê´€ë ¨ ë¬¸ì„œ ì¼ë¶€ì…ë‹ˆë‹¤:\n\n"
                f"{context}\n\n"
                "ìœ„ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ, ì•„ë˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n\n"
                f"ì§ˆë¬¸: {query}"
            )

        try:
            completion = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content},
                ],
                timeout=30.0,  # íƒ€ì„ì•„ì›ƒ 30ì´ˆ ì„¤ì •
            )
        except RateLimitError as e:
            logger.error(f"OpenAI Rate Limit ì—ëŸ¬: {e}")
            raise HTTPException(
                status_code=429,
                detail="ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        except APITimeoutError as e:
            logger.error(f"OpenAI Timeout ì—ëŸ¬: {e}")
            raise HTTPException(
                status_code=504,
                detail="ìš”ì²­ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        except APIConnectionError as e:
            logger.error(f"OpenAI ì—°ê²° ì—ëŸ¬: {e}")
            raise HTTPException(
                status_code=503,
                detail="AI ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        except APIError as e:
            logger.error(f"OpenAI API ì—ëŸ¬: {e}")
            raise HTTPException(
                status_code=502,
                detail="AI ì„œë¹„ìŠ¤ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            )

        reply_text = completion.choices[0].message.content

        # fallback ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ ì•ì— ì‚´ì§ ë¶™ì´ê¸°
        if fallback:
            reply_text = fallback + "\n\n" + reply_text

        # ë¡œê·¸ ê¸°ë¡
        try:
            log_chat(
                user_message=req.message,
                reply=reply_text,
                meta={
                    "model": "gpt-4o-mini",
                    "source": "openai",
                    "mode": "rag",
                    "docs_used": [m.get("source") for m in metas] if metas else [],
                },
            )
        except Exception as e:
            logger.warning(f"ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

        return ChatResponse(reply=reply_text)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ (/api/rag-chat): {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail="RAG ê¸°ë°˜ ë‹µë³€ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )


# 3) ìµœê·¼ ë¡œê·¸ ì¡°íšŒ (ì˜µì…˜)
@app.get("/api/logs/recent")
def get_recent_logs(limit: int = 20):
    """ìµœê·¼ ëŒ€í™” ë¡œê·¸ nê°œ ì¡°íšŒ (ê¸°ë³¸ 20ê°œ)"""
    if not LOG_PATH.exists():
        return []

    lines = LOG_PATH.read_text(encoding="utf-8").splitlines()
    data = [json.loads(line) for line in lines[-limit:]]
    return data